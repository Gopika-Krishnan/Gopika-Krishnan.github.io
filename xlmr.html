<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Cross-Lingual Transfer of Acceptability Judgement</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Gopika Krishnan</a>
				<nav>
					<ul>
                        <li><a href="index.html" class="active">Home</a></li>
                        <li><a href="https://github.com/Gopika-Krishnan" class="active">GitHub</a></li>

					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper style3">
						<div class="inner">
                            <h1 class="major">Cross-Lingual Transfer of Acceptability Judgement
                            </h1>
                            <h3><span style="color:#BB000E;font-weight: bold;"> LING-UA 52-001 Machine Learning for Language Understanding (NYU Courant Institute of Mathematical Sciences) </span><span style="font-weight:bold;color:#0f0f0f;" ><br>Spring 2021 Group Project of 2</span><br>
                            </h3>
                            
                              <p style="display:inline;">
                                Many recent studies have attempted to evaluate the grammatical knowledge acquired by language models. While most of these studies focus on English, models trained on multi-lingual corpora have also demonstrated success in transferring grammatical knowledge between languages (Mueller et al., 2020). Many studies on the transfer of grammatical knowledge evaluate models such as LSTMs and mBERT (Devlin et al., 2019), yet few have studied the grammatical abilities of the new state-of-the-art XLM-R model (Conneau et al., 2020). In this paper, we evaluate the ability of XLM-R to learn and transfer grammatical knowledge from a source language (English) to 4 
                                % similar and dissimilar 
                                target languages (German, Hebrew, French and Russian) using the datasets created by Mueller et al., 2020. Furthermore, we test the model on a low-resource language (Nepali). The fine-tuned model achieves a perfect accuracy in English and an average accuracy greater that 80\% in every other language. In Nepali, its accuracy on simple agreement is greater that 85\%. Our results demonstrate that XLM-R can successfully transfer grammatical knowledge from English to other languages. We also find evidence that the average accuracy of each language is correlated with the size of the corpora used for that language during the pre-training of XLM-R. <br></p>
                                <br>
                                <ul class="actions">
                                    
                                    <li><a href="https://github.com/reem-hazim/cross-lingual-transfer-xlmr" class="button primary" style="color:#b35858;">GitHub</a></li>
                                  
                                </ul>
                         </div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Gopika Krishnan. All rights reserved.</li><li>Design inspired by: HTML5up</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>